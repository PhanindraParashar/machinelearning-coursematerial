{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The bootstrap\n",
    "\n",
    "The **bootstrap** is a popular method in statistics, used to estimate the uncertainty associated with an estimator.\n",
    "In our case, you will have guessed, we want to estimate the quality of a model --- for example, we might want to estimate the MSE of a regression model, as in the previous classes.\n",
    "It is an additional technique, alternative to cross-validation, to perform model validation.\n",
    "\n",
    "The main idea is to train the model on a set of $n$ observations, where $n$ is the size of our data set.\n",
    "But, in this case, where are we going to find data for the test set?\n",
    "The answer is that we can artificially create a training set as large as the whole data set, by sampling $n$ points from it, *with repetition*.\n",
    "In this way, there might be points that are taken multiple times, as well as points which are not taken at all.\n",
    "The set of points which have not been taken will then form our test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But can we expect to have enough of these points?\n",
    "We can easily figure this out.\n",
    "The chance that a data point will be selected when extracting a sample is $\\frac{1}{n}$.\n",
    "Therefore, the chance of a data point *not* being selected during one extraction is $1 - \\frac{1}{n}$.\n",
    "Because we sample from the data set $n$ times independently, the probability that a point is not selected in any of the $n$ extractions is $\\big( 1 - \\frac{1}{n} \\big)^n$.\n",
    "If we take the limit $n \\to \\infty$ of this quantity, we can see that it is $e^{-1} \\approx 0.368$.\n",
    "So, if we have a large enough dataset, roughly 36.8% of the points will not be sampled and the test set size will be approximately 36.8% of the full dataset size.\n",
    "\n",
    "To make the result robust, we can repeat the bootstrapping procedure $B$ times and, each time, sample the dataset with replacement.\n",
    "What is the error associated with such a method?\n",
    "Let $\\hat{Y}^{(b)}_i$ be the prediction for the label associated with test data point $X_i$, obtained with the model trained during the $b$-th repetition of the bootstrap procedure.\n",
    "This means that during the $b$-th iteration point $X_i$ ended up in the test set because it was not sampled for the training set.\n",
    "\n",
    "To make a concrete example: imagine we are using bootstrap and we are at the first iteration ($b = 1$).\n",
    "Let $D$ represent the whole data-set: $D = \\{ (X_1, Y_1), \\ldots, (X_n, Y_n) \\}$.\n",
    "Let $\\bar{D}^{(1)}$ be the set of points which were not sampled in the first iteration of the bootstrap.\n",
    "Therefore, the model has been trained on a set of $n$ points which belong to the set $D \\setminus \\bar{D}^{(1)}$ (with repetitions).\n",
    "The set $\\bar{D}^{(1)}$ will now be used as our test set.\n",
    "For each point $(X_i, Y_i) \\in \\bar{D}^{(1)}$, we can calulate the prediction $\\hat{Y}^{(1)}_i$ and then the squared error $\\big( Y_i - \\hat{Y}^{(1)}_i \\big)^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeat the same for the second, third, etc. bootstrap iterations.\n",
    "At iteration $b$ we'll have a set $\\bar{D}^{(b)}$ of points not sampled, which will be our test set.\n",
    "For each point in that test set, we can calculate the squared error.\n",
    "\n",
    "When we want to evaluate the MSE of the method we should average the squared error of each point.\n",
    "But any given point $(X_i, Y_i)$ was in the test set only for some iterations of the bootstrap (when it was not sampled to end up in the training set).\n",
    "So, for each point $(X_i, Y_i)$ there will be only a subset of bootstrap iterations that will give us the error relative to that point.\n",
    "Let's call $C_i$ the indices of those bootstrap iterations when $(X_i, Y_i)$ was in the test set.\n",
    "The average error relative to $(X_i, Y_i)$ is then:\n",
    "\n",
    "$$\\text{SE}_i = \\frac{1}{|C_i|} \\sum_{b \\in C_i} \\bigg( \\hat{Y}^{(b)}_i - Y_i \\bigg)^2 \\quad \\text{ (or } 0 \\text{ if } C_i = \\emptyset\\text{)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the error estimation is computed, as in the \"regular\" MSE calculation, by averaging over all the points in the dataset:\n",
    "\n",
    "$$\\text{Error}_{\\,\\text{bootstrap}} = \\frac{1}{n} \\sum_{i=1}^n \\text{SE}_i = \\frac{1}{n} \\sum_{i = 1}^n \\frac{1}{|C_i|} \\sum_{b \\in C_i} \\bigg( \\hat{Y}^{(b)}_i - Y_i \\bigg)^2$$\n",
    "\n",
    "This estimation is called the **out-of-bag error** because, at each iteration, the points which have not been drawn are called *out-of-bag* samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small example\n",
    "\n",
    "Imagine we have a data-set:\n",
    "$$D = \\{ (X_1, Y_1), (X_2, Y_2), (X_3, Y_3), (X_4, Y_4), (X_5, Y_5) \\}$$\n",
    "and we make three bootstrap iterations.\n",
    "\n",
    "1. In the first iteration, the training set is:\n",
    "$$\\{ (X_1, Y_1), (X_4, Y_4), (X_1, Y_1), (X_3, Y_3), (X_4, Y_4) \\}$$\n",
    "Where we can see that some point are repeated more than once, while others are missing completely.\n",
    "The corresponding test set is given by all the points which were not sampled for training:\n",
    "$$\\bar{D}^{(1)} = \\{ (X_2, Y_2), (X_5, Y_5) \\}$$\n",
    "The model is trained and then is asked to produce a prediction for each point in the training set.\n",
    "This means, it will be used to obtain predictions $\\hat{Y}_2^{(1)}$ and $\\hat{Y}_5^{(1)}$.\n",
    "2. In the second iteration we have the training set:\n",
    "$$\\{ (X_4, Y_4), (X_2, Y_2), (X_2, Y_2), (X_1, Y_1), (X_2, Y_2) \\}$$\n",
    "and, therfore, the test set is:\n",
    "$$\\bar{D}^{(2)} = \\{ (X_3, Y_3), (X_5, Y_5) \\}$$\n",
    "and the predictions we get from the second model are $\\hat{Y}_3^{(2)}$ and $\\hat{Y}_5^{(2)}$.\n",
    "3. Finally, in the last iteration we have the training set:\n",
    "$$\\{ (X_5, Y_5), (X_2, Y_2), (X_2, Y_2), (X_3, Y_3), (X_5, Y_5) \\}$$\n",
    "the test set is:\n",
    "$$\\bar{D}^{(3)} = \\{ (X_1, Y_1), (X_4, Y_4) \\}$$\n",
    "and the predictions from the third models are $\\hat{Y}^{(3)}$ and $\\hat{Y}_4^{(3)}$.\n",
    "\n",
    "We can now calculate what are the sets $C_i$ for each of the 5 points in the data-set.\n",
    "Because the first point $(X_1, Y_1)$ was in the test set only at the third bootstrap iteration, we have $C_1 = \\{3\\}$.\n",
    "Analogously, $(X_2, Y_2)$ was in the test set in the first iteration only, so $C_2 = \\{1\\}$.\n",
    "Continuing, $C_3 = \\{2\\}$, $C_4 = \\{5\\}$, and $C_5 = \\{1,2\\}$ because point $(X_5, Y_5)$ was in the test set at both iterations 1 and 2.\n",
    "\n",
    "So, if we want to know the mean square error relative to point $(X_5, Y_5)$ we should average the two square errors we can obtain with the predictions at the first and second bootstrap iteration:\n",
    "$$\\text{SE}_5 = \\frac{1}{|C_5|} \\sum_{b \\in C_5} \\Big( \\hat{Y}_5^{(b)} - Y_5 \\Big)^2 = \\frac{1}{2} \\bigg( \\Big( \\hat{Y}_5^{(1)} - Y_5 \\Big)^2 + \\Big( \\hat{Y}_5^{(2)} - Y_5 \\Big)^2 \\bigg)$$\n",
    "If we want to know $\\text{SE}_1$, this is going to be even easier, because we only have one iteration which produced an estimation for point $(X_1, Y_1)$, so there is \"nothing\" to average.\n",
    "And the same is true, in this small example, also for $\\text{SE}_2, \\text{SE}_3, \\text{SE}_4$.\n",
    "\n",
    "Finally, the overall estimation is given by averaging $\\text{SE}_1, \\ldots, \\text{SE}_5$.\n",
    "In our small example, this is:\n",
    "$$\\text{Error}_\\text{Bootstrap} = \\frac{1}{5} \\bigg(\n",
    "    \\big( \\hat{Y}_1^{(3)} - Y_1 \\big)^2 +\n",
    "    \\big( \\hat{Y}_2^{(1)} - Y_1 \\big)^2 +\n",
    "    \\big( \\hat{Y}_3^{(2)} - Y_1 \\big)^2 +\n",
    "    \\big( \\hat{Y}_4^{(5)} - Y_1 \\big)^2 +\n",
    "    \\frac{1}{2} \\big( (\\hat{Y}_5^{(1)} - Y_1)^2 + (\\hat{Y}_5^{(2)} - Y_1)^2 \\big)\n",
    "\\bigg)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitations of the Bootstrap\n",
    "\n",
    "Since each bootstrap sample (training set) has $n$ data points but, on average, only $\\sim \\, n \\cdot 0.632$ of them are distinct, the training set does not adequately represent the distribution of the original data.\n",
    "This problem is similar to the one we would have if we did validation by splitting the total data-set into a training and test sets with a rough 63%-37% proportion.\n",
    "Because the model is trained on roughly $n \\cdot 0.632$ distinct points over the $n$ available, it will perform slightly worse than a model that can be trained on the whole data set.\n",
    "For this reason, $\\text{Error}_{\\,\\text{bootstrap}}$ often overestimates the true MSE of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overcome this problem, a new estimate of the error has been proposed.\n",
    "It is called the **0.632 method** and it consists of averaging an overestimated and an underestimated value for the true error, to obtain a more accurate prediction.\n",
    "Concretely, the error is estimated as:\n",
    "\n",
    "$$\\text{Error}_{\\,0.632} = 0.632 \\cdot \\text{Error}_{\\,\\text{Bootstrap}} + 0.368 \\cdot \\text{Error}_{\\,\\text{Training}}$$\n",
    "\n",
    "Where $\\text{Error}_{\\,\\text{Training}}$ is the training MSE when we use the whole dataset as training set:\n",
    "\n",
    "$$\\text{Error}_{\\,\\text{Training}} = \\frac{1}{n} \\sum_{i=1}^n (\\hat{Y}_i - Y_i)^2$$\n",
    "\n",
    "(In the formula above, $\\hat{Y}_i$ is the prediction for the $i$-th data point given by the model trained on the whole data set.)\n",
    "Notice how $\\text{Error}_{\\,\\text{Bootstrap}}$ tends to overestimate the true error, while $\\text{Error}_{\\,\\text{Training}}$ tends to underestimate it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonus: the 0.632+ method\n",
    "\n",
    "If the model is prone to overfit over the entire dataset, $\\text{Error}_{\\,\\text{Train}}$ will be very low.\n",
    "In that case, the \"0.368\" component will prevail and $\\text{Error}_{\\,0.632}$ will also underestimate the true error.\n",
    "To prevent this situation, a new method called the **0.632+ method** was developed.\n",
    "The new estimator looks as follows:\n",
    "\n",
    "$$\\text{Error}_{\\,0.632+} = w \\cdot \\text{Error}_{\\,\\text{Bootstrap}} + (1 - w) \\cdot \\text{Error}_{\\,\\text{Training}}$$\n",
    "\n",
    "Where\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "    w &= \\frac{0.632}{1 - 0.368 \\cdot R} \\\\\n",
    "    \\\\\n",
    "    R &= \\frac{\\text{Error}_{\\,\\text{Bootstrap}} - \\text{Error}_{\\,\\text{Training}}}{\\gamma - \\text{Error}_{\\,\\text{Training}}} \\\\\n",
    "    \\\\\n",
    "    \\gamma &= \\frac{1}{n^2} \\sum_{i=1}{n} \\sum_{j=1}{n} (\\hat{Y}_j - Y_i)^2 = \\text{\"no-information error rate\"}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style(\"darkgrid\")\n",
    "matplotlib.rcParams['figure.figsize'] = (14, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation, as we have done before.\n",
    "d = pd.read_csv('../data/auto-mpg.csv')\n",
    "label_column = 'mpg'\n",
    "feature_columns = [c for c in d.columns if c != label_column]\n",
    "X = d[feature_columns].values\n",
    "y = d[label_column].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the Quadratic regression + LASSO model from previous classes\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PolynomialFeatures(degree = 2),\n",
    "    Lasso(alpha = 0.0316, max_iter = 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "import numpy as np\n",
    "\n",
    "# Number of bootstrap iterations; the larger, the better.\n",
    "bootstrap_iterations = 1000\n",
    "\n",
    "# Indices of all points in the dataset.\n",
    "dataset_indices = range(len(X))\n",
    "\n",
    "# This list of lists will contain the square errors:\n",
    "# sq_errors[12][5], for example, will contain the square error\n",
    "# between the true label of point number 12 ans the prediction\n",
    "# made at the 5-th bootstrap iteration where point number 12\n",
    "# ended up in the test set.\n",
    "sq_errors = [list() for _ in dataset_indices]\n",
    "\n",
    "for b in range(bootstrap_iterations):\n",
    "    # Indices of the points which will form the training set.\n",
    "    # It will likely contain duplicates, because we sample with replacement.\n",
    "    # It has the same size as the full dataset.\n",
    "    training_indices = resample(dataset_indices, replace = True, n_samples = len(X), random_state = b)\n",
    "    \n",
    "    # Indices of the out-of-bag points: those points not sampled\n",
    "    # for the training set. It contains roughly 36.8% of the points.\n",
    "    test_indices = [i for i in dataset_indices if i not in training_indices]\n",
    "    \n",
    "    # We take training and test data according to the above indices.\n",
    "    X_train, y_train = X[training_indices], y[training_indices]\n",
    "    X_test, y_test = X[test_indices], y[test_indices]\n",
    "    \n",
    "    # We train the model on the training data...\n",
    "    model.fit(X_train, y_train)\n",
    "    # ...and calculate predictions on the testa data.\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # We save the squared errors in `sq_errors`.\n",
    "    for pred_index, point_index in enumerate(test_indices):\n",
    "        sq_err = (predictions[pred_index] - y_test[pred_index]) ** 2\n",
    "        sq_errors[point_index].append(sq_err)\n",
    "    \n",
    "# We compute, for each point, its average square error.\n",
    "# This correspond to the inner sum in the definition of Error_Bootstrap.\n",
    "sq_errors_by_point = [sum(x) / len(x) if len(x) > 0 else 0 for x in sq_errors]\n",
    "\n",
    "# We compute the bootstrap estimate of the MSE.\n",
    "# We called this Error_Bootstrap in the explanation above.\n",
    "bootstrap_error = np.mean(sq_errors_by_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE (estimated by bootstrap): 8.041\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model MSE (estimated by bootstrap): {bootstrap_error:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, as expected, the estimate is pessimistic because we used models trained on roughly 63.2% of the data.\n",
    "We can also easily compute the 0.632-bootstrap error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model.fit(X, y)\n",
    "all_training_predictions = model.predict(X)\n",
    "training_error = mean_squared_error(y, all_training_predictions)\n",
    "bootstrap_632_error = 0.632 * bootstrap_error + 0.368 * training_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model MSE (estimated by the 0.632-bootstrap method): 7.532\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model MSE (estimated by the 0.632-bootstrap method): {bootstrap_632_error:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the estimates we have seen in previous classes, we can perhaps convince ourselves that this is a better estimation of the true MSE of our Quadratic regression + LASSO model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
